import os 
import cv2
import pickle 
import numpy as np 
from sklearn.preprocessing import Normalizer
from tensorflow.keras.models import load_model
from architecture import *
import tkinter.messagebox as tm
import io
from Crypto.Cipher import AES
from Crypto import Random
from PIL import Image


def get_pickel_encoding():
    face_data = 'Dataset'
    required_shape = (160,160)
    face_encoder = InceptionResNetV2()
    path = "facenet_keras_weights.h5"
    face_encoder.load_weights(path)
    encodes = []
    encoding_dict = dict()
    l2_normalizer = Normalizer('l2')
          
    def decrypt(path,image_path,key,iv):

        enc_file2 = open(image_path, 'rb')
        enc_data2 = enc_file2.read()
        enc_file2.close()
        cfb_decipher = AES.new(key, AES.MODE_CFB, iv)
        plain_data = cfb_decipher.decrypt(enc_data2)
        image = Image.open(io.BytesIO(plain_data))
        return np.asarray(image)

                
    def normalize(img):
        mean, std = img.mean(), img.std()
        return (img - mean) / std
    for face_names in os.listdir(face_data):
        person_dir = os.path.join(face_data,face_names)
        if (os.path.isdir(person_dir)):
            person_files=os.listdir(person_dir)
            #Now for every person we will first load the key from pickle file
            key_val=[os.path.join(person_dir,each) for each in person_files if each.endswith('.pickle')][0] 
            #Once we have loaded the pickle file we will delete the file from our list. Now we have
            #only encrypted images in our Person's folder
            person_files.remove('key.pickle')
            with open(key_val, 'rb') as f:
                key,iv = pickle.load(f)
            for image_name in person_files:
                image_path = os.path.join(person_dir,image_name)
                #we get the decrypted image
                img_RGB=decrypt(person_dir,image_path,key,iv)
                img_RGB = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2RGB)
                face = normalize(img_RGB)
                face = cv2.resize(face, required_shape)
                face_d = np.expand_dims(face, axis=0)
                #We get the encodings, which are unique for each person.
                encode = face_encoder.predict(face_d)[0]
                encodes.append(encode)
            
            if encodes:
                encode = np.sum(encodes, axis=0)
                encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]
                encoding_dict[face_names] = encode
    path = 'encodings.pkl'
    with open(path, 'wb') as file:
        pickle.dump(encoding_dict, file)
    tm.showinfo("Success", "Model Trained successfully")

    
    
    
    
    
    

